{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86bba5f-06a1-4cf9-b9bd-006c040e2d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reasoning_from_scratch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m torch.__version__\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mreasoning_from_scratch\u001b[49m.__version__\n",
      "\u001b[31mNameError\u001b[39m: name 'reasoning_from_scratch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "reasoning_from_scratch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de36b927-ee24-418f-b978-943e9fa241a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.10.0\n",
      "Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    " \n",
    "print(f\"PyTorch version {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA GPU\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Only CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724b8c2-bfd3-40ca-b6e1-25f02b1dfb5c",
   "metadata": {},
   "source": [
    "## Download Tokenizer Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4074876f-090e-43c7-a448-a21bedfdc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reasoning_from_scratch.qwen3 import download_qwen3_small\n",
    "download_qwen3_small(kind=\"base\", tokenizer_only=True, out_dir=\"qwen3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614a3cb-8eee-49ce-8da9-5597dde38b01",
   "metadata": {},
   "source": [
    "## load the tokenizer settings from the tokenizer file into the Qwen3Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a0e220-c3a7-40e1-b7a4-4eba1c5e3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from reasoning_from_scratch.qwen3 import Qwen3Tokenizer\n",
    " \n",
    "tokenizer_path = Path(\"qwen3\") / \"tokenizer-base.json\"\n",
    "tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b0ab6f-97d3-4458-a9f5-b166383c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain large language models\"\n",
    "input_token_ids_list = tokenizer.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf2cc5be-95d0-4f56-a35a-381f9ad47bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[840, 20772, 3460, 4128, 4119, 595, 5604, 685, 4360]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23195ef1-39a6-4b1c-870b-250495344a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain large language models khamiaza\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(input_token_ids_list)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b4e78d6-df7f-4e1a-827b-f4d8a1e663ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[840] --> Ex\n",
      "[20772] --> plain\n",
      "[3460] -->  large\n",
      "[4128] -->  language\n",
      "[4119] -->  models\n",
      "[595] -->  k\n",
      "[5604] --> ham\n",
      "[685] --> ia\n",
      "[4360] --> za\n"
     ]
    }
   ],
   "source": [
    "for i in input_token_ids_list:\n",
    "    print(f\"{[i]} --> {tokenizer.decode([i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bc2b4-bb58-4b63-9758-88e1541883f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
